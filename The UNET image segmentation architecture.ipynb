{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc4f0b6b-26d2-432a-b68d-d22c8878f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82066a78-00fa-4d2c-8538-acc05e68e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "IMG_SIZE = 480 \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def preprocess_data(example):\n",
    "    # Extract image and segmentation mask\n",
    "    image = example['image']\n",
    "    mask = example['segmentation_mask']\n",
    "    \n",
    "    # Resize image and mask\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    mask = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    # Normalize image to [0, 1] range\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    # Ensure mask is in integer format (not one-hot encoded)\n",
    "    mask = tf.cast(mask, tf.uint8)\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "# Load the COCO dataset\n",
    "dataset, info = tfds.load('coco/2017', split='train', with_info=True, shuffle_files=True)\n",
    "\n",
    "# Preprocess the dataset\n",
    "dataset = dataset.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Print the dataset info and the first batch for verification\n",
    "print(info)\n",
    "\n",
    "for images, masks in dataset.take(1):\n",
    "    print(f'Image batch shape: {images.shape}')\n",
    "    print(f'Mask batch shape: {masks.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efac9298-d0b6-4639-ad2b-cb9b3e79233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
    "    \"\"\"\n",
    "    Convolutional downsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        inputs -- Input tensor\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "        dropout_prob -- Dropout probability\n",
    "        max_pooling -- MaxPooling2D to reduce the spatial dimensions of the output volume\n",
    "    Returns: \n",
    "        next_layer, skip_connection --  Next layer and skip connection outputs\n",
    "    \"\"\"\n",
    "    conv = Conv2D(n_filters, 3,  activation= \"relu\", padding=\"same\", kernel_initializer='he_normal')(inputs)\n",
    "    conv = Conv2D(n_filters, 3,   activation=\"relu\", padding=\"same\", kernel_initializer= 'he_normal')(conv)\n",
    "    \n",
    "    if dropout_prob > 0:\n",
    "        conv = Dropout(dropout_prob)(conv)\n",
    "        \n",
    "    if max_pooling:\n",
    "        next_layer = MaxPooling2D((2,2))(conv)\n",
    "        \n",
    "    else:\n",
    "        next_layer = conv\n",
    "        \n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aef6bc6-9790-4997-9a14-c02794c172b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
    "    \"\"\"\n",
    "    Convolutional upsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        expansive_input -- Input tensor from previous layer\n",
    "        contractive_input -- Input tensor from previous skip layer\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "    Returns: \n",
    "        conv -- Tensor output\n",
    "    \"\"\"\n",
    "\n",
    "    up = Conv2DTranspose( n_filters,   3,   strides=(2,2), padding=\"same\")(expansive_input)\n",
    "    \n",
    "    # Merge the previous output and the contractive_input\n",
    "    merge = concatenate([up, contractive_input], axis=3)\n",
    "    conv = Conv2D(n_filters,   (3,3),   activation=\"relu\",padding=\"same\",kernel_initializer='he_normal')(merge)\n",
    "    conv = Conv2D(n_filters,  (3,3),  activation=\"relu\",padding=\"same\",kernel_initializer=\"he_normal\")(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1fae48b-ec25-4118-bc6a-15784cae7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(96, 128, 3), n_filters=32, n_classes=23):\n",
    "    \"\"\"\n",
    "    Unet model\n",
    "    \n",
    "    Arguments:\n",
    "        input_size -- Input shape \n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "        n_classes -- Number of output classes\n",
    "    Returns: \n",
    "        model -- tf.keras.Model\n",
    "    \"\"\"\n",
    "    inputs = Input(input_size)\n",
    "    cblock1 = conv_block(inputs, n_filters)\n",
    "    # the first element of the output of each block to be the input of the next conv_block is chained\n",
    "    # number of filters at each new step is doubled\n",
    "    cblock2 = conv_block(cblock1[0], n_filters*2)\n",
    "    cblock3 = conv_block(cblock2[0], n_filters*4)\n",
    "    cblock4 = conv_block(cblock3[0], n_filters*8, dropout_prob=0.3) # Include a dropout_prob of 0.3 for this layer\n",
    "    # dropout_prob of 0.3 for this layer, and avoid the max_pooling layer\n",
    "    cblock5 = conv_block(cblock4[0], n_filters*16, dropout_prob=0.3, max_pooling=False) \n",
    "    \n",
    "    # the first upsampling_block.\n",
    "    # cblock5[0] as expansive_input and cblock4[1] as contractive_input and n_filters * 8\n",
    "    ublock6 = upsampling_block(cblock5[0], cblock4[1],  n_filters*8)\n",
    "   \n",
    "    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters*4)\n",
    "    ublock8 = upsampling_block(ublock7, cblock2[1],  n_filters*2)\n",
    "    ublock9 = upsampling_block(ublock8, cblock1[1],  n_filters)\n",
    "\n",
    "    conv9 = Conv2D(n_filters,3,activation='relu',padding='same',kernel_initializer='he_normal')(ublock9)\n",
    "\n",
    "    # A Conv2D layer with n_classes filter, kernel size of 1 and a 'same' padding\n",
    "    conv10 = Conv2D(n_classes, 1, padding=\"same\")(conv9)\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e3a282-edd1-454a-a392-4d3dcb511836",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 480\n",
    "img_width = 480\n",
    "num_channels = 3\n",
    "\n",
    "unet = unet_model((img_height, img_width, num_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f63bc6-109e-4596-a5a7-0355b52bd366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 480, 480, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 480, 480, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 480, 480, 32  9248        ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 240, 240, 32  0           ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 240, 240, 64  18496       ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 240, 240, 64  36928       ['conv2d_2[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 120, 120, 64  0          ['conv2d_3[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 120, 120, 12  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 120, 120, 12  147584      ['conv2d_4[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 60, 60, 128)  0          ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 60, 60, 256)  295168      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 60, 60, 256)  590080      ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 60, 60, 256)  0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 30, 30, 256)  0          ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 30, 30, 512)  1180160     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 30, 30, 512)  2359808     ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 30, 30, 512)  0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 60, 60, 256)  1179904    ['dropout_1[0][0]']              \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 60, 60, 512)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 60, 60, 256)  1179904     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 60, 60, 256)  590080      ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 120, 120, 12  295040     ['conv2d_11[0][0]']              \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 120, 120, 25  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                6)                                'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 120, 120, 12  295040      ['concatenate_1[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 120, 120, 12  147584      ['conv2d_12[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 240, 240, 64  73792      ['conv2d_13[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 240, 240, 12  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                8)                                'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 240, 240, 64  73792       ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 240, 240, 64  36928       ['conv2d_14[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 480, 480, 32  18464      ['conv2d_15[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 480, 480, 64  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                )                                 'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 480, 480, 32  18464       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 480, 480, 32  9248        ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 480, 480, 32  9248        ['conv2d_17[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 480, 480, 23  759         ['conv2d_18[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,640,471\n",
      "Trainable params: 8,640,471\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0e9c9-ca51-4a99-baf6-2237f6142d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de9d70-8a94-494a-b655-57990a6bae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BUFFER_SIZE = 500\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "print(dataset.element_spec)\n",
    "model_history = unet.fit(train_dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3bb9ef-5f7f-4643-aea6-667992d47416",
   "metadata": {},
   "source": [
    "### In the following cells, I will load the pretrained HRNETV2 model and make some masking prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c60675-05c5-46a9-ba16-2ad90b3c2f58",
   "metadata": {},
   "source": [
    "##### -The model I built above has 8,640,471 trainable parameters. The Coco dataset has morethan 25000 images. If I am to train the model from scratch on my CPU, it would take days if not weeks to fit the the coco data. I will be loading the model from: tensorflow tensorflow-hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868ce17-0045-40ad-8900-bfbf96f95c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-hub\n",
    "!pip install --upgrade tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ddcd1-1c7d-449a-b71e-18f5e2ed4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import tensorflow as tf\n",
    "model_url =  'https://tfhub.dev/google/HRNet/camvid-hrnetv2-w48/1'\n",
    "\n",
    "print('loading model: ', model_url)\n",
    " \n",
    "model = hub.load(model_url)\n",
    "print('\\nmodel loaded!')\n",
    " # colormap for 32 classes\n",
    "colors = [\n",
    "    (0, 0, 0), (128, 64, 128), (244, 35, 232), (70, 70, 70),\n",
    "    (102, 102, 156), (190, 153, 153), (153, 153, 153), (250, 170, 30),\n",
    "    (220, 220, 0), (107, 142, 35), (152, 251, 152), (250, 0, 12), \n",
    "    (70, 130, 180), (220, 20, 60), (255, 0, 0), (0, 0, 142),\n",
    "    (0, 0, 70),(0, 60, 100), (0, 80, 100), (0, 0, 230),\n",
    "    (119, 11, 32), (250, 0, 0), (13, 8, 135), (17, 35, 175),\n",
    "    (18, 66, 218), (14, 102, 241), (25, 136, 252), (60, 164, 252),\n",
    "    (112, 186, 245), (183, 206, 236), (238, 219, 225), (254, 236, 198)]\n",
    "\n",
    "# a colormap from the list of colors\n",
    "colormap = ListedColormap(colors)\n",
    "\n",
    "def preprocess_image(image_path, target_size=(512, 512)):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "def predict_mask(model, image):\n",
    "    prediction = model(image)\n",
    "    print(prediction.shape)\n",
    "    predicted_mask = tf.argmax(prediction, axis=-1)\n",
    "    print(np.max(predicted_mask))\n",
    "    print(predicted_mask.shape)\n",
    "    return predicted_mask\n",
    "\n",
    "\n",
    "#image_path = r\"C:\\Users\\robel\\Downloads\\pedestrian.jpg\"\n",
    "image_path = r\"C:\\Users\\robel\\Downloads\\cycle.png\"\n",
    "#image_path = r\"C:\\Users\\robel\\Downloads\\voc_ex.jpg\"\n",
    "image = preprocess_image(image_path)\n",
    "predicted_mask = predict_mask(model, image)\n",
    "\n",
    "\n",
    "# Map normalized values to colors\n",
    "predicted_mask = tf.squeeze(predicted_mask, axis=0)\n",
    "print(predicted_mask.shape)\n",
    "predicted_mask = tf.cast(predicted_mask, tf.float32)\n",
    "print(predicted_mask.shape, predicted_mask)\n",
    "image = tf.squeeze(image, axis=0)\n",
    "image = image.numpy()*255 # Convert back to [0, 255] range\n",
    "\n",
    "# Normalize the class IDs to [0, 1] range\n",
    "num_classes = len(colors)\n",
    "normalized_mask = predicted_mask / (num_classes - 1)\n",
    "print(normalized_mask.shape)\n",
    "# Map normalized values to colors\n",
    "colored_mask = colormap(normalized_mask)\n",
    "print(\"Colormap output:\", colored_mask)\n",
    "print(\"Colormap output type:\", type(colored_mask))\n",
    "# Extract only the RGB channels from the colored_mask\n",
    "if colored_mask.shape[-1] == 4:  # Check if the mask has an alpha channel\n",
    "    colored_mask = colored_mask[:, :, :3]  # Remove the alpha channel\n",
    "\n",
    "# Resize colored_mask to match the size of the original image\n",
    "colored_mask = cv2.resize(colored_mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Blend images\n",
    "alpha = 0.4\n",
    "image = image.astype('int32')\n",
    "colored_mask = colored_mask.astype('int32')\n",
    "print(image.shape, colored_mask.shape)\n",
    "blended_image = cv2.addWeighted(image, alpha, colored_mask, 1 - alpha, 0)\n",
    "\n",
    "# Display the result\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Predicted Mask with Colors\")\n",
    "plt.imshow(blended_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(colored_mask)\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
